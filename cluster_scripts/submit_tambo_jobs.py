#!/usr/bin/env python3
import argparse
import math
import os
import random
import subprocess
from pathlib import Path
from datetime import datetime
import textwrap
import sys

# ---------- configuration ----------

# Energy limits
E_MIN = 1e5
E_MAX = 5e7
NUM_BINS = 100

# Base paths
BASE_OUTPUT_DIR = "/n/netscratch/arguelles_delgado_lab/Everyone/hhanif/tambo_simulation_nov_25"
# Updated: args and logs are now inside BASE_OUTPUT_DIR
ARGS_DIR_DEFAULT = os.path.join(BASE_OUTPUT_DIR, "args_batches")
LOGS_DIR_DEFAULT = os.path.join(BASE_OUTPUT_DIR, "logs")
SCRIPT_OUT_DEFAULT = os.path.join(BASE_OUTPUT_DIR, "scripts", "run_tambo_batch.sh")

# ---------- helpers ----------

def loguniform(a, b):
    return 10 ** random.uniform(math.log10(a), math.log10(b))

def fmt_float(x):
    return f"{x:.4e}"  # Scientific notation for cleaner folder names

def random_seed_5digits():
    return random.randint(10000, 99999)

def get_pdg_flags(pdg_id):
    """Returns the interaction/decay flag based on PDG ID."""
    mesons = [211, -211, 111]
    electrons = [11, -11]
    
    if pdg_id in mesons:
        return ""
    elif pdg_id in electrons:
        return "--force-interaction"
    else:
        # Should be caught by argparse choices, but just in case
        raise ValueError(f"PDG {pdg_id} logic not defined.")

def get_energy_folder_name(energy):
    """
    Calculates which 'bin' the energy falls into to create consistent 
    folder names (100 bins total).
    """
    log_min = math.log10(E_MIN)
    log_max = math.log10(E_MAX)
    log_step = (log_max - log_min) / NUM_BINS
    
    # Calculate bin index
    log_e = math.log10(energy)
    bin_idx = int((log_e - log_min) / log_step)
    
    # Clamp index to handle floating point edge cases at max energy
    bin_idx = min(bin_idx, NUM_BINS - 1)
    
    # Calculate bin edges for the folder name
    bin_lower = 10 ** (log_min + bin_idx * log_step)
    bin_upper = 10 ** (log_min + (bin_idx + 1) * log_step)
    
    return f"energy_{bin_lower:.2e}_to_{bin_upper:.2e}"

def build_command(idx_within_job, pdg_id, pdg_flag):
    energy  = loguniform(E_MIN, E_MAX)
    azimuth = random.uniform(0.0, 6.3)
    zenith  = random.uniform(0.0, 3.14)
    seed    = random_seed_5digits()

    # Determine folder structure
    # Structure: /base/pdg_XXX/energy_A_to_B/filename
    energy_folder = get_energy_folder_name(energy)
    full_output_dir = Path(BASE_OUTPUT_DIR) / f"pdg_{pdg_id}" / energy_folder
    
    # Ensure filename is unique
    tag = "${SLURM_JOB_ID}_" + str(idx_within_job)
    output_filename = full_output_dir / tag

    # We add a mkdir command to the line to ensure the folder exists 
    # before the C++ simulation tries to write to it.
    cmd = (
        f"mkdir -p {full_output_dir} && "
        "./c8_air_shower "
        f"--energy {energy:.8g} "
        "--injection-height 4000 "
        f"--filename {output_filename} "
        f"--pdg {pdg_id} "
        f"--zenith {zenith:.8g} "
        f"--azimuth {azimuth:.8g} "
        f"--seed {seed} "
        "--emcut 1.0 --hadcut 1.0 --mucut 1.0 --taucut 1.0 "
        f"{pdg_flag}"
    )
    return cmd

def write_args_file(path: Path, n_lines: int, pdg_id: int):
    pdg_flag = get_pdg_flags(pdg_id)
    lines = [build_command(i+1, pdg_id, pdg_flag) for i in range(n_lines)]
    
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w") as f:
        f.write("# Auto-generated by submit_tambo_jobs.py\n")
        for line in lines:
            f.write(line + "\n")
    return len(lines)

def render_bash_template(log_dir):
    # Added 'timeout 30m' and logic to catch exit code 124 (timeout)
    # Replaced hardcoded log paths with __LOG_DIR__ placeholder
    template = textwrap.dedent("""\
        #!/bin/bash
        #SBATCH --job-name=tambo_simulation
        #SBATCH --mem=32G
        #SBATCH --time=7-00:00
        #SBATCH --output=__LOG_DIR__/%j.out
        #SBATCH --error=__LOG_DIR__/%j.err
        #SBATCH -p arguelles_delgado

        # Record overall start time
        total_start=$(date +%s)

        cd /n/holylfs05/LABS/arguelles_delgado_lab/Everyone/hhanif/
        source /n/holylfs05/LABS/arguelles_delgado_lab/Everyone/hhanif/virtual/environment/corsika-8/bin/activate

        module load gcc/13.2.0-fasrc01 cmake/3.31.6-fasrc01

        export CORSIKA_PREFIX=/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/hhanif/corsika_package/
        export CONAN_DEPENDENCIES=${CORSIKA_PREFIX}/corsika-install/lib/cmake/dependencies
        export FLUPRO=/n/holylfs05/LABS/arguelles_delgado_lab/Lab/common_software/source/fluka
        export FLUFOR=gfortransbatch
        export WITH_FLUKA=ON

        cd /n/holylfs05/LABS/arguelles_delgado_lab/Everyone/hhanif/corsika_package/corsika-install/bin

        # ---- loop over commands ----
        input_file="${INPUT_FILE}"
        if [[ -f "$input_file" ]]; then
            echo "Running simulations from $input_file..."
            sim_count=0
            while IFS= read -r line; do
                [[ -z "$line" || "$line" =~ ^# ]] && continue
                sim_count=$((sim_count + 1))
                echo
                echo "========== Simulation #$sim_count =========="
                echo "Command: $line"
                
                start_time=$(date +%s)
                
                # RUN COMMAND WITH 30 MINUTE TIMEOUT
                # 'eval' is used to handle the 'mkdir && ./command' structure
                timeout 30m bash -c "$line"
                exit_code=$?
                
                end_time=$(date +%s)
                duration=$((end_time - start_time))
                
                if [ $exit_code -eq 124 ]; then
                    # 124 is the standard exit code for GNU timeout
                    echo "!!! Simulation taking so much time or stuck moving to another simulation !!!"
                elif [ $exit_code -ne 0 ]; then
                    echo "Simulation failed with exit code $exit_code"
                else
                    printf "Runtime for simulation #%d: %02d:%02d (mm:ss)\\n" "$sim_count" $((duration/60)) $((duration%60))
                fi
                echo "==========================================="
            done < "$input_file"
        else
            echo "Error: Input file $input_file not found!"
            exit 1
        fi

        # ---- total timing ----
        total_end=$(date +%s)
        total_runtime=$((total_end - total_start))
        echo
        echo "==========================================="
        printf "Total runtime for all simulations: %02d:%02d (mm:ss)\\n" $((total_runtime/60)) $((total_runtime%60))
        echo "==========================================="
        """)
    return template.replace("__LOG_DIR__", str(log_dir))

def write_bash_script(script_path: Path, overwrite: bool):
    if script_path.exists() and not overwrite:
        return False
    script_path.parent.mkdir(parents=True, exist_ok=True)
    with open(script_path, "w") as f:
        # Pass the global LOGS_DIR_DEFAULT to the template
        f.write(render_bash_template(LOGS_DIR_DEFAULT))
    os.chmod(script_path, 0o755)
    return True

def submit_job(script_path: Path, args_file: Path, extra_sbatch=None, dry_run=False):
    cmd = ["sbatch"]
    if extra_sbatch:
        cmd += extra_sbatch
    cmd += [f"--export=ALL,INPUT_FILE={args_file}", str(script_path)]

    if dry_run:
        print("$ " + " ".join(cmd))
        return None

    proc = subprocess.run(cmd, text=True, capture_output=True)
    if proc.returncode != 0:
        msg = []
        if proc.stdout.strip():
            msg.append("STDOUT:\n" + proc.stdout.strip())
        if proc.stderr.strip():
            msg.append("STDERR:\n" + proc.stderr.strip())
        raise RuntimeError("sbatch failed (exit {}):\n{}".format(proc.returncode, "\n".join(msg)))
    print(proc.stdout.strip())
    return proc.stdout.strip()

# ---------- main ----------

def main():
    parser = argparse.ArgumentParser(
        description="Generate random TAMBO args with structured output, 30min timeout, and auto-submission."
    )
    # New PDG Argument
    parser.add_argument("--pdg", type=int, required=True, choices=[211, -211, 111, 11, -11],
                        help="Particle ID. Mesons (211, -211, 111). Electrons (11, -11) use --force-interaction.")
    
    parser.add_argument("--jobs", type=int, default=1, help="Number of Slurm jobs to submit.")
    parser.add_argument("--sims-per-job", type=int, default=10, help="Simulations per job.")
    parser.add_argument("--args-dir", default=ARGS_DIR_DEFAULT,
                        help="Directory for generated per-job args files.")
    parser.add_argument("--script-out", default=SCRIPT_OUT_DEFAULT,
                        help="Where to write the generated SBATCH script.")
    parser.add_argument("--overwrite-script", action="store_true",
                        help="Overwrite the generated script if it already exists.")
    parser.add_argument("--seed", type=int, default=None,
                        help="RNG seed for reproducibility (optional).")
    parser.add_argument("--sbatch-flags", nargs=argparse.REMAINDER,
                        help="Extra sbatch flags. Example: --sbatch-flags --qos high")
    parser.add_argument("--dry-run", action="store_true", help="Print actions without submitting.")
    
    args = parser.parse_args()

    if args.seed is not None:
        random.seed(args.seed)

    args_dir = Path(args.args_dir)
    script_path = Path(args.script_out)
    
    # Updated: Use the BASE_OUTPUT_DIR subfolder for logs
    logs_dir = Path(LOGS_DIR_DEFAULT)
    logs_dir.mkdir(parents=True, exist_ok=True)

    # Validate PDG Logic (Double check logic is available, though choices handles validity)
    try:
        flag_used = get_pdg_flags(args.pdg)
        print(f"PDG: {args.pdg} selected. Using flag: {flag_used}")
    except ValueError as e:
        print(f"Error: {e}")
        sys.exit(1)

    # Write or reuse the autogen bash script
    created = write_bash_script(script_path, overwrite=args.overwrite_script)
    if created:
        print(f"Wrote SBATCH script -> {script_path}")
    else:
        print(f"Using existing SBATCH script -> {script_path}")

    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    total = args.jobs * args.sims_per_job
    print(f"Preparing {args.jobs} jobs × {args.sims_per_job} sims/job (total {total})")
    
    submitted = []
    for j in range(1, args.jobs + 1):
        args_file = args_dir / f"args_{args.pdg}_{ts}_job{j}.txt"
        
        # Pass PDG ID to the writer
        n = write_args_file(args_file, args.sims_per_job, args.pdg)
        
        print(f"  • Wrote {n} commands -> {args_file}")
        out = submit_job(script_path, args_file, extra_sbatch=args.sbatch_flags, dry_run=args.dry_run)
        if out:
            submitted.append({"job": j, "sbatch": out, "args_file": str(args_file)})

    if args.dry_run:
        print("\n(DRY RUN) Done. No jobs submitted.")
    else:
        print("\nSubmitted jobs:")
        for s in submitted:
            print(f"  - job#{s['job']}: {s['sbatch']}  (args: {s['args_file']})")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"ERROR: {e}", file=sys.stderr)
        sys.exit(1)