#!/usr/bin/env python3
import argparse
import math
import os
import random
import subprocess
from pathlib import Path
from datetime import datetime
import textwrap
import sys

# ---------- configuration ----------

# Energy limits
E_MIN = 1e5
E_MAX = 5e7
NUM_BINS = 100

# Base paths
BASE_OUTPUT_DIR = "/n/netscratch/arguelles_delgado_lab/Everyone/hhanif/tambo_simulation_nov_25"
ARGS_DIR_DEFAULT = os.path.join(BASE_OUTPUT_DIR, "args_batches")
LOGS_DIR_DEFAULT = os.path.join(BASE_OUTPUT_DIR, "logs")
SCRIPT_OUT_DEFAULT = os.path.join(BASE_OUTPUT_DIR, "scripts", "run_tambo_batch.sh")

# ---------- helpers ----------

def loguniform(a, b):
    return 10 ** random.uniform(math.log10(a), math.log10(b))

def fmt_float(x):
    return f"{x:.4e}"

def random_seed_5digits():
    return random.randint(10000, 99999)

def get_pdg_flags(pdg_id):
    """Returns the interaction/decay flag based on PDG ID."""
    mesons = [211, -211, 111]
    electrons = [11, -11]
    
    if pdg_id in mesons:
        return ""
    elif pdg_id in electrons:
        return "--force-interaction"
    else:
        raise ValueError(f"PDG {pdg_id} logic not defined.")

def get_energy_folder_name(energy):
    """Calculates which 'bin' the energy falls into."""
    log_min = math.log10(E_MIN)
    log_max = math.log10(E_MAX)
    log_step = (log_max - log_min) / NUM_BINS
    
    log_e = math.log10(energy)
    bin_idx = int((log_e - log_min) / log_step)
    bin_idx = min(bin_idx, NUM_BINS - 1)
    
    bin_lower = 10 ** (log_min + bin_idx * log_step)
    bin_upper = 10 ** (log_min + (bin_idx + 1) * log_step)
    
    return f"energy_{bin_lower:.2e}_to_{bin_upper:.2e}"

def build_command(idx_within_job, pdg_id, pdg_flag):
    energy  = loguniform(E_MIN, E_MAX)
    azimuth = random.uniform(0.0, 6.3)
    zenith  = random.uniform(0.0, 3.14)
    seed    = random_seed_5digits()

    energy_folder = get_energy_folder_name(energy)
    full_output_dir = Path(BASE_OUTPUT_DIR) / f"pdg_{pdg_id}" / energy_folder
    
    tag = "${SLURM_JOB_ID}_" + str(idx_within_job)
    output_filename = full_output_dir / tag

    cmd = (
        f"mkdir -p {full_output_dir} && "
        "./c8_air_shower "
        f"--energy {energy:.8g} "
        "--injection-height 4000 "
        f"--filename {output_filename} "
        f"--pdg {pdg_id} "
        f"--zenith {zenith:.8g} "
        f"--azimuth {azimuth:.8g} "
        f"--seed {seed} "
        "--emcut 1.0 --hadcut 1.0 --mucut 1.0 --taucut 1.0 "
        f"{pdg_flag}"
    )
    return cmd

def write_args_file(path: Path, n_lines: int, pdg_id: int):
    pdg_flag = get_pdg_flags(pdg_id)
    lines = [build_command(i+1, pdg_id, pdg_flag) for i in range(n_lines)]
    
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w") as f:
        f.write("# Auto-generated by submit_tambo_jobs.py\n")
        for line in lines:
            f.write(line + "\n")
    return len(lines)

def render_bash_template(log_dir, partition, time_limit, memory):
    """
    Renders the bash script with dynamic SLURM headers.
    """
    template = textwrap.dedent("""\
        #!/bin/bash
        #SBATCH --job-name=tambo_simulation
        #SBATCH --mem=__MEM__
        #SBATCH --time=__TIME__
        #SBATCH --output=__LOG_DIR__/%j.out
        #SBATCH --error=__LOG_DIR__/%j.err
        #SBATCH -p __PARTITION__

        # Record overall start time
        total_start=$(date +%s)

        cd /n/holylfs05/LABS/arguelles_delgado_lab/Everyone/hhanif/
        source /n/holylfs05/LABS/arguelles_delgado_lab/Everyone/hhanif/virtual/environment/corsika-8/bin/activate

        module load gcc/13.2.0-fasrc01 cmake/3.31.6-fasrc01

        export CORSIKA_PREFIX=/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/hhanif/corsika_package/
        export CONAN_DEPENDENCIES=${CORSIKA_PREFIX}/corsika-install/lib/cmake/dependencies
        export FLUPRO=/n/holylfs05/LABS/arguelles_delgado_lab/Lab/common_software/source/fluka
        export FLUFOR=gfortransbatch
        export WITH_FLUKA=ON

        cd /n/holylfs05/LABS/arguelles_delgado_lab/Everyone/hhanif/corsika_package/corsika-install/bin

        # ---- loop over commands ----
        input_file="${INPUT_FILE}"
        if [[ -f "$input_file" ]]; then
            echo "Running simulations from $input_file..."
            sim_count=0
            while IFS= read -r line; do
                [[ -z "$line" || "$line" =~ ^# ]] && continue
                sim_count=$((sim_count + 1))
                echo
                echo "========== Simulation #$sim_count =========="
                echo "Command: $line"
                
                start_time=$(date +%s)
                
                # RUN COMMAND WITH 35 MINUTE TIMEOUT
                timeout 35m bash -c "$line"
                exit_code=$?
                
                end_time=$(date +%s)
                duration=$((end_time - start_time))
                
                if [ $exit_code -eq 124 ]; then
                    echo "!!! Simulation taking so much time or stuck moving to another simulation !!!"
                elif [ $exit_code -ne 0 ]; then
                    echo "Simulation failed with exit code $exit_code"
                else
                    printf "Runtime for simulation #%d: %02d:%02d (mm:ss)\\n" "$sim_count" $((duration/60)) $((duration%60))
                fi
                echo "==========================================="
            done < "$input_file"
        else
            echo "Error: Input file $input_file not found!"
            exit 1
        fi

        # ---- total timing ----
        total_end=$(date +%s)
        total_runtime=$((total_end - total_start))
        echo
        echo "==========================================="
        printf "Total runtime for all simulations: %02d:%02d (mm:ss)\\n" $((total_runtime/60)) $((total_runtime%60))
        echo "==========================================="
        """)
    
    # Replace placeholders
    script = template.replace("__LOG_DIR__", str(log_dir))
    script = script.replace("__PARTITION__", partition)
    script = script.replace("__TIME__", time_limit)
    script = script.replace("__MEM__", memory)
    
    return script

def write_bash_script(script_path: Path, overwrite: bool, partition: str, time_limit: str, memory: str):
    if script_path.exists() and not overwrite:
        return False
    
    script_path.parent.mkdir(parents=True, exist_ok=True)
    with open(script_path, "w") as f:
        # Generate the content dynamically
        content = render_bash_template(LOGS_DIR_DEFAULT, partition, time_limit, memory)
        f.write(content)
        
    os.chmod(script_path, 0o755)
    return True

def submit_job(script_path: Path, args_file: Path, extra_sbatch=None, dry_run=False):
    cmd = ["sbatch"]
    if extra_sbatch:
        cmd += extra_sbatch
    cmd += [f"--export=ALL,INPUT_FILE={args_file}", str(script_path)]

    if dry_run:
        print("$ " + " ".join(cmd))
        return None

    proc = subprocess.run(cmd, text=True, capture_output=True)
    if proc.returncode != 0:
        msg = []
        if proc.stdout.strip():
            msg.append("STDOUT:\n" + proc.stdout.strip())
        if proc.stderr.strip():
            msg.append("STDERR:\n" + proc.stderr.strip())
        raise RuntimeError("sbatch failed (exit {}):\n{}".format(proc.returncode, "\n".join(msg)))
    print(proc.stdout.strip())
    return proc.stdout.strip()

# ---------- main ----------

def main():
    parser = argparse.ArgumentParser(
        description="Generate random TAMBO args with structured output, timeout, and auto-submission."
    )
    # Required PDG
    parser.add_argument("--pdg", type=int, required=True, choices=[211, -211, 111, 11, -11],
                        help="Particle ID. Mesons (211, -211, 111). Electrons (11, -11).")
    
    # SLURM Configs
    parser.add_argument("--partition", "-p", default="shared", 
                        choices=["shared", "arguelles_delgado", "serial_requeue"],
                        help="SLURM partition to use. Affects time limit.")
    
    parser.add_argument("--mem", default="8G",
                        help="Memory allocation per job (e.g., 8G, 16G, 32G). Default: 16G")

    # Job Control
    parser.add_argument("--jobs", type=int, default=1, help="Number of Slurm jobs to submit.")
    parser.add_argument("--sims-per-job", type=int, default=10, help="Simulations per job.")
    parser.add_argument("--args-dir", default=ARGS_DIR_DEFAULT, help="Directory for args files.")
    parser.add_argument("--script-out", default=SCRIPT_OUT_DEFAULT, help="Output path for SBATCH script.")
    parser.add_argument("--overwrite-script", action="store_true", help="Overwrite generated script.")
    parser.add_argument("--seed", type=int, default=None, help="RNG seed.")
    parser.add_argument("--sbatch-flags", nargs=argparse.REMAINDER, help="Extra sbatch flags.")
    parser.add_argument("--dry-run", action="store_true", help="Print actions without submitting.")
    
    args = parser.parse_args()

    if args.seed is not None:
        random.seed(args.seed)

    args_dir = Path(args.args_dir)
    script_path = Path(args.script_out)
    logs_dir = Path(LOGS_DIR_DEFAULT)
    logs_dir.mkdir(parents=True, exist_ok=True)

    # Validate PDG
    try:
        flag_used = get_pdg_flags(args.pdg)
        print(f"PDG: {args.pdg} selected. Using flag: {flag_used}")
    except ValueError as e:
        print(f"Error: {e}")
        sys.exit(1)

    # Determine Time Limit based on Partition
    if args.partition == "arguelles_delgado":
        time_limit = "7-00:00"
    else:
        # shared or serial_requeue
        time_limit = "3-00:00"

    print(f"Config: Partition={args.partition}, Time={time_limit}, Mem={args.mem}")

    # Write SBATCH script
    created = write_bash_script(
        script_path, 
        overwrite=args.overwrite_script,
        partition=args.partition,
        time_limit=time_limit,
        memory=args.mem
    )

    if created:
        print(f"Wrote SBATCH script -> {script_path}")
    else:
        print(f"Using existing SBATCH script -> {script_path}")
        print("  (Note: Use --overwrite-script if you changed partition/mem args)")

    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    total = args.jobs * args.sims_per_job
    print(f"Preparing {args.jobs} jobs × {args.sims_per_job} sims/job (total {total})")
    
    submitted = []
    for j in range(1, args.jobs + 1):
        args_file = args_dir / f"args_{args.pdg}_{ts}_job{j}.txt"
        
        n = write_args_file(args_file, args.sims_per_job, args.pdg)
        
        print(f"  • Wrote {n} commands -> {args_file}")
        out = submit_job(script_path, args_file, extra_sbatch=args.sbatch_flags, dry_run=args.dry_run)
        if out:
            submitted.append({"job": j, "sbatch": out, "args_file": str(args_file)})

    if args.dry_run:
        print("\n(DRY RUN) Done. No jobs submitted.")
    else:
        print("\nSubmitted jobs:")
        for s in submitted:
            print(f"  - job#{s['job']}: {s['sbatch']}  (args: {s['args_file']})")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"ERROR: {e}", file=sys.stderr)
        sys.exit(1)